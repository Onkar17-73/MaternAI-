{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3474b338158a4dca9c1e2972377df5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f52770d35819468d9cb6bc5b59d6228c",
              "IPY_MODEL_94831b589a6d44c58e456d5dc2417a3f",
              "IPY_MODEL_fba0328aa554480f991e74575e51ff98"
            ],
            "layout": "IPY_MODEL_0845da2e22ab4a509bf88700891dcfc9"
          }
        },
        "f52770d35819468d9cb6bc5b59d6228c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2a26cd90024ae4b2a4a9b4aee86d90",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_05f301ba6ad54e08ae1e8e0eb0d74caf",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "94831b589a6d44c58e456d5dc2417a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38524ac667c14369960a2df0c0ccdfae",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_484700c33ce34c439e59cb63c73a70a0",
            "value": 2
          }
        },
        "fba0328aa554480f991e74575e51ff98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3aa3e39e6364bc2acd6d8d563e77790",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dd1b6844745c4b3aa1eda51e0144276f",
            "value": "â€‡2/2â€‡[01:15&lt;00:00,â€‡34.99s/it]"
          }
        },
        "0845da2e22ab4a509bf88700891dcfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2a26cd90024ae4b2a4a9b4aee86d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f301ba6ad54e08ae1e8e0eb0d74caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38524ac667c14369960a2df0c0ccdfae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484700c33ce34c439e59cb63c73a70a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3aa3e39e6364bc2acd6d8d563e77790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1b6844745c4b3aa1eda51e0144276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7A2tUhOB7TV",
        "outputId": "c251f5d2-c19a-4c7a-938d-022b47e3c4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 18 18:45:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-VmMP_tDxtJ",
        "outputId": "da16a2b4-cc18-4551-fe1e-78373fc2ff1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # First, install ngrok and other requirements\n",
        "!pip install flask googletrans==3.1.0a0 gtts peft transformers torch accelerate\n",
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xvf ngrok-v3-stable-linux-amd64.tgz\n",
        "!mv ngrok /usr/local/bin\n",
        "\n",
        "# Ensure you have your ngrok authtoken (you'll need to sign up at ngrok.com to get one)\n",
        "import getpass\n",
        "print(\"Enter your ngrok authtoken (sign up at ngrok.com):\")\n",
        "authtoken = getpass.getpass()\n",
        "!ngrok authtoken $authtoken\n",
        "\n",
        "import os\n",
        "import random\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer, GenerationConfig\n",
        "import torch\n",
        "from threading import Thread\n",
        "from flask import Response\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Initialize the Falcon model\n",
        "class BookFinetunedFalcon:\n",
        "    def __init__(self, model_path, device=\"cuda\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            low_cpu_mem_usage=True,\n",
        "            return_dict=True,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=device\n",
        "        )\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        self.generation_config = GenerationConfig(\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            top_k=50,\n",
        "            max_new_tokens=512,\n",
        "            min_new_tokens=50,\n",
        "            num_beams=1,\n",
        "            repetition_penalty=1.2,\n",
        "            length_penalty=1.0,\n",
        "            no_repeat_ngram_size=3,\n",
        "            pad_token_id=self.tokenizer.eos_token_id,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    def generate_response(self, prompt, max_length=None):\n",
        "        formatted_prompt = (\n",
        "            \"### Human: Given the following question about pregnancy and maternity, \"\n",
        "            \"provide a detailed and accurate response:\\n\\n\"\n",
        "            f\"{prompt}\\n\\n\"\n",
        "            \"### Assistant: Based on medical knowledge about pregnancy and maternity, \"\n",
        "            \"here is my response:\"\n",
        "        )\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            formatted_prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        if max_length:\n",
        "            self.generation_config.max_new_tokens = max_length\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    generation_config=self.generation_config\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            response = response.split(\"### Assistant:\")[-1].strip()\n",
        "            response = response.replace(\"###\", \"\").strip()\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "# Initialize global variables\n",
        "model = None\n",
        "translator = Translator()\n",
        "\n",
        "# Language mapping\n",
        "LANGUAGES = {\n",
        "    'hi': {'name': 'Hindi', 'code': 'hi'},\n",
        "    'ta': {'name': 'Tamil', 'code': 'ta'},\n",
        "    'te': {'name': 'Telugu', 'code': 'te'},\n",
        "    'ml': {'name': 'Malayalam', 'code': 'ml'},\n",
        "    'kn': {'name': 'Kannada', 'code': 'kn'},\n",
        "    'mr': {'name': 'Marathi', 'code': 'mr'},\n",
        "    'gu': {'name': 'Gujarati', 'code': 'gu'},\n",
        "    'bn': {'name': 'Bengali', 'code': 'bn'}\n",
        "}\n",
        "\n",
        "def safe_translate(text, src_lang, dest_lang):\n",
        "    try:\n",
        "        # Get response from Falcon model (in English)\n",
        "        global model\n",
        "        if model is None:\n",
        "            model = BookFinetunedFalcon(\n",
        "                \"onkar234567/falcon-maternity-model\",\n",
        "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            )\n",
        "\n",
        "        # First translate input to English if not already in English\n",
        "        if src_lang != 'en':\n",
        "            to_english = translator.translate(text, src=src_lang, dest='en')\n",
        "            english_text = to_english.text\n",
        "        else:\n",
        "            english_text = text\n",
        "\n",
        "        # Get model response\n",
        "        model_response = model.generate_response(english_text)\n",
        "\n",
        "        # Translate model response to target language\n",
        "        if dest_lang != 'en':\n",
        "            translated_response = translator.translate(model_response, src='en', dest=dest_lang)\n",
        "            final_response = translated_response.text\n",
        "        else:\n",
        "            final_response = model_response\n",
        "\n",
        "        return {\n",
        "            'original_input': text,\n",
        "            'english_translation': english_text,\n",
        "            'translated_response': final_response\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'original_input': text,\n",
        "            'english_translation': f\"Translation error: {str(e)}\",\n",
        "            'translated_response': f\"Error: {str(e)}\"\n",
        "        }\n",
        "\n",
        "# Create HTML template string\n",
        "html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>MaternAI</title>\n",
        "    <link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        .chat-container {\n",
        "            max-height: 500px;\n",
        "            overflow-y:auto;\n",
        "        }\n",
        "        .message {\n",
        "            max-width: 80%;\n",
        "        }\n",
        "        .user-message {\n",
        "            background-color: #E6F2FF;\n",
        "            align-self: flex-end;\n",
        "        }\n",
        "        .bot-message {\n",
        "            background-color: #F0F0F0;\n",
        "            align-self: flex-start;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body class=\"bg-gray-100\">\n",
        "    <div class=\"container mx-auto px-4 py-8 max-w-2xl\">\n",
        "        <div class=\"bg-white shadow-lg rounded-lg overflow-hidden\">\n",
        "            <div class=\"p-4 bg-blue-500 text-white text-center\">\n",
        "                <h1 class=\"text-2xl font-bold\">MaternAI</h1>\n",
        "                <p class=\"text-sm mt-2\">Ask questions about pregnancy and maternity care in your preferred language</p>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"p-4 flex space-x-2\">\n",
        "                <select id=\"language\" class=\"flex-grow p-2 border rounded\">\n",
        "                    <option value=\"hi-IN\">Hindi (India)</option>\n",
        "                    <option value=\"ta-IN\">Tamil (India)</option>\n",
        "                    <option value=\"te-IN\">Telugu (India)</option>\n",
        "                    <option value=\"ml-IN\">Malayalam (India)</option>\n",
        "                    <option value=\"kn-IN\">Kannada (India)</option>\n",
        "                    <option value=\"mr-IN\">Marathi (India)</option>\n",
        "                    <option value=\"gu-IN\">Gujarati (India)</option>\n",
        "                    <option value=\"bn-IN\">Bengali (India)</option>\n",
        "                </select>\n",
        "                <button id=\"startRecording\" class=\"bg-green-500 text-white px-4 py-2 rounded hover:bg-green-600\">\n",
        "                    ðŸŽ¤ Start Voice\n",
        "                </button>\n",
        "                <button id=\"stopRecording\" disabled class=\"bg-red-500 text-white px-4 py-2 rounded hover:bg-red-600\">\n",
        "                    â—¼ Stop\n",
        "                </button>\n",
        "            </div>\n",
        "\n",
        "            <div id=\"status\" class=\"p-2 text-center text-gray-600\"></div>\n",
        "\n",
        "            <div id=\"chatContainer\" class=\"chat-container p-4 space-y-4 flex flex-col\">\n",
        "                <div class=\"message bot-message self-start p-3 rounded-lg\">\n",
        "                    ðŸ‘‹ Hi! I'm your multilingual maternity assistant. Ask me any questions about pregnancy and maternal health.\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"p-4 border-t\">\n",
        "                <div class=\"flex space-x-2\">\n",
        "                    <input type=\"text\" id=\"textInput\" placeholder=\"Type your question about pregnancy or maternity...\"\n",
        "                           class=\"flex-grow p-2 border rounded\">\n",
        "                    <button id=\"sendText\" class=\"bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600\">\n",
        "                        Send\n",
        "                    </button>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <audio id=\"responseAudio\" class=\"hidden\"></audio>\n",
        "    </div>\n",
        "        <script>\n",
        "        const startButton = document.getElementById('startRecording');\n",
        "        const stopButton = document.getElementById('stopRecording');\n",
        "        const statusDiv = document.getElementById('status');\n",
        "        const chatContainer = document.getElementById('chatContainer');\n",
        "        const languageSelect = document.getElementById('language');\n",
        "        const responseAudio = document.getElementById('responseAudio');\n",
        "        const textInput = document.getElementById('textInput');\n",
        "        const sendTextButton = document.getElementById('sendText');\n",
        "\n",
        "        // Map language codes to translation codes\n",
        "        const LANGUAGE_MAP = {\n",
        "            'hi-IN': 'hi',\n",
        "            'ta-IN': 'ta',\n",
        "            'te-IN': 'te',\n",
        "            'ml-IN': 'ml',\n",
        "            'kn-IN': 'kn',\n",
        "            'mr-IN': 'mr',\n",
        "            'gu-IN': 'gu',\n",
        "            'bn-IN': 'bn'\n",
        "        };\n",
        "\n",
        "        // Check browser support\n",
        "        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n",
        "        if (!SpeechRecognition) {\n",
        "            statusDiv.textContent = 'Speech recognition not supported';\n",
        "            startButton.disabled = true;\n",
        "        }\n",
        "\n",
        "        const recognition = new SpeechRecognition();\n",
        "        recognition.continuous = false;\n",
        "        recognition.interimResults = false;\n",
        "\n",
        "        function addMessageToChatContainer(message, type, audioPaths = null) {\n",
        "            const messageElement = document.createElement('div');\n",
        "            messageElement.classList.add(\n",
        "                'message',\n",
        "                type === 'user' ? 'user-message' : 'bot-message',\n",
        "                'self-' + (type === 'user' ? 'end' : 'start'),\n",
        "                'p-3', 'rounded-lg'\n",
        "            );\n",
        "            messageElement.textContent = message;\n",
        "\n",
        "            // Add audio playback button if audio is available\n",
        "            if (audioPaths && audioPaths.audio_path) {\n",
        "                const playButton = document.createElement('button');\n",
        "                playButton.textContent = 'ðŸ”Š Listen';\n",
        "                playButton.classList.add('ml-2', 'bg-blue-500', 'text-white', 'px-2', 'py-1', 'rounded', 'text-sm');\n",
        "                playButton.addEventListener('click', () => {\n",
        "                    responseAudio.src = audioPaths.audio_path;\n",
        "                    responseAudio.play();\n",
        "                });\n",
        "                messageElement.appendChild(playButton);\n",
        "            }\n",
        "\n",
        "            chatContainer.appendChild(messageElement);\n",
        "            chatContainer.scrollTop = chatContainer.scrollHeight;\n",
        "        }\n",
        "\n",
        "        function processInput(voiceInput) {\n",
        "            const languageCode = languageSelect.value;\n",
        "            const translationCode = LANGUAGE_MAP[languageCode];\n",
        "\n",
        "            statusDiv.textContent = 'Processing input...';\n",
        "\n",
        "            addMessageToChatContainer(voiceInput, 'user');\n",
        "\n",
        "            const formData = new FormData();\n",
        "            formData.append('voice_input', voiceInput);\n",
        "            formData.append('language', translationCode);\n",
        "\n",
        "            fetch('/process', {\n",
        "                method: 'POST',\n",
        "                body: formData\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                addMessageToChatContainer(data.translated_response, 'bot', data);\n",
        "\n",
        "                statusDiv.textContent = 'Processing complete';\n",
        "            })\n",
        "            .catch(error => {\n",
        "                addMessageToChatContainer('Sorry, an error occurred.', 'bot');\n",
        "                statusDiv.textContent = 'Error processing input';\n",
        "                console.error('Error:', error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Set language for speech recognition based on dropdown\n",
        "        recognition.onstart = () => {\n",
        "            const selectedLang = languageSelect.value;\n",
        "            recognition.lang = selectedLang;\n",
        "\n",
        "            statusDiv.textContent = 'Listening... Speak now';\n",
        "            startButton.disabled = true;\n",
        "            stopButton.disabled = false;\n",
        "        };\n",
        "\n",
        "        recognition.onresult = (event) => {\n",
        "            const voiceInput = event.results[0][0].transcript;\n",
        "            processInput(voiceInput);\n",
        "        };\n",
        "\n",
        "        recognition.onerror = (event) => {\n",
        "            statusDiv.textContent = 'Error occurred in recognition: ' + event.error;\n",
        "            startButton.disabled = false;\n",
        "            stopButton.disabled = true;\n",
        "        };\n",
        "\n",
        "        recognition.onend = () => {\n",
        "            statusDiv.textContent = 'Voice input ended';\n",
        "            startButton.disabled = false;\n",
        "            stopButton.disabled = true;\n",
        "        };\n",
        "\n",
        "        startButton.addEventListener('click', () => {\n",
        "            try {\n",
        "                recognition.start();\n",
        "            } catch (error) {\n",
        "                statusDiv.textContent = 'Error starting recognition: ' + error;\n",
        "            }\n",
        "        });\n",
        "\n",
        "        stopButton.addEventListener('click', () => {\n",
        "            recognition.stop();\n",
        "        });\n",
        "\n",
        "        sendTextButton.addEventListener('click', () => {\n",
        "            const inputText = textInput.value.trim();\n",
        "            if (inputText) {\n",
        "                processInput(inputText);\n",
        "                textInput.value = '';\n",
        "            }\n",
        "        });\n",
        "\n",
        "        textInput.addEventListener('keypress', (e) => {\n",
        "            if (e.key === 'Enter') {\n",
        "                const inputText = textInput.value.trim();\n",
        "                if (inputText) {\n",
        "                    processInput(inputText);\n",
        "                    textInput.value = '';\n",
        "                }\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return html_template\n",
        "\n",
        "@app.route('/process', methods=['POST'])\n",
        "def process_input():\n",
        "    try:\n",
        "        voice_input = request.form.get('voice_input', '').strip()\n",
        "        target_language = request.form.get('language', 'hi')\n",
        "\n",
        "        translation_result = safe_translate(voice_input, target_language, target_language)\n",
        "\n",
        "        tts = gTTS(text=translation_result['translated_response'], lang=target_language)\n",
        "\n",
        "        os.makedirs('static', exist_ok=True)\n",
        "        audio_path = f'static/response_{target_language}_{random.randint(1000,9999)}.mp3'\n",
        "        tts.save(audio_path)\n",
        "\n",
        "        translation_result['audio_path'] = audio_path\n",
        "\n",
        "        return jsonify(translation_result)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "def run_ngrok():\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "    # Set up ngrok tunnel\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f' * Public URL: {public_url}')\n",
        "\n",
        "def run_app():\n",
        "    app.run(port=5000)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Initialize model\n",
        "    print(\"Initializing Falcon model...\")\n",
        "    model = BookFinetunedFalcon(\n",
        "        \"onkar234567/falcon-maternity-model\",\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    )\n",
        "\n",
        "    # Start ngrok in a separate thread\n",
        "    from pyngrok import ngrok\n",
        "    ngrok_thread = Thread(target=run_ngrok)\n",
        "    ngrok_thread.start()\n",
        "\n",
        "    # Start Flask app\n",
        "    print(\"Starting Flask application...\")\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3474b338158a4dca9c1e2972377df5fe",
            "f52770d35819468d9cb6bc5b59d6228c",
            "94831b589a6d44c58e456d5dc2417a3f",
            "fba0328aa554480f991e74575e51ff98",
            "0845da2e22ab4a509bf88700891dcfc9",
            "bc2a26cd90024ae4b2a4a9b4aee86d90",
            "05f301ba6ad54e08ae1e8e0eb0d74caf",
            "38524ac667c14369960a2df0c0ccdfae",
            "484700c33ce34c439e59cb63c73a70a0",
            "f3aa3e39e6364bc2acd6d8d563e77790",
            "dd1b6844745c4b3aa1eda51e0144276f"
          ]
        },
        "id": "XJkagcQ8CQOV",
        "outputId": "bef46a9d-d145-411a-bd94-89807641e784"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.12.14)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "--2024-12-18 19:00:29--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.71.179.82, 75.2.60.68, 99.83.220.108, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.71.179.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14796857 (14M) [application/octet-stream]\n",
            "Saving to: â€˜ngrok-v3-stable-linux-amd64.tgz.1â€™\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]  14.11M  71.5MB/s    in 0.2s    \n",
            "\n",
            "2024-12-18 19:00:30 (71.5 MB/s) - â€˜ngrok-v3-stable-linux-amd64.tgz.1â€™ saved [14796857/14796857]\n",
            "\n",
            "ngrok\n",
            "Enter your ngrok authtoken (sign up at ngrok.com):\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Initializing Falcon model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3474b338158a4dca9c1e2972377df5fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Flask application...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Public URL: NgrokTunnel: \"https://e156-34-148-67-68.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:02:29] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:02:30] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:03:20] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:03:28] \"\u001b[35m\u001b[1mGET /static/response_hi_5441.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:03:29] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:04:50] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:05:10] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:05:56] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:06:19] \"\u001b[35m\u001b[1mGET /static/response_hi_4721.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:06:19] \"\u001b[35m\u001b[1mGET /static/response_hi_4721.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:06:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:06:45] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:07:15] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:07:20] \"\u001b[35m\u001b[1mGET /static/response_hi_2601.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:07:22] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:08:28] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:08:34] \"POST /process HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:09:00] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:09:04] \"\u001b[35m\u001b[1mGET /static/response_hi_5179.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:09:05] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:11:16] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:11:16] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:11:23] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:11:44] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:11:50] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:12:31] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:12:54] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:13:12] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:13:12] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:15:13] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:15:43] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:15:50] \"\u001b[35m\u001b[1mGET /static/response_hi_8727.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:15:51] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:16:01] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:16:19] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:16:24] \"\u001b[35m\u001b[1mGET /static/response_hi_4391.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:16:25] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Dec/2024 19:17:51] \"POST /process HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}